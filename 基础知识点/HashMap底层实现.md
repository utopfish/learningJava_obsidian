HashMap 基于 Map 接口实现，元素以键值对的方式存储，并且允许使用 null 建和 null 值，　因为 key 不允许重复，因此只能有一个键为 null ,另外 HashMap 不能保证放入元素的顺序，它是无序的，和放入的顺序并不能相同。 HashMap 是**线程不安全**的。

JDK1.8 之前 HashMap 由数组+链表组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。JDK1.8 以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。
## 装载因子和动态扩容
HashMap 的初始容量为 16， Hashtable 初始容量为 11 ，两者的填充因子默认都是 0.75。 HashMap 扩容时是当前容量翻倍即: capacity\*2， Hashtable 扩容时是容量翻倍+1即: capacity\*2+1。
![[装载因子0.75.png]]
当 map 中包含的 Entry 的数量大于等于 threshold = loadFactor * capacity 的时候，且新建的 Entry 刚好落在一个非空的桶上，此刻触发扩容机制，将其容量扩大为 2 倍。


## 冲突解决
在 JDK1.8之前， HashMap 底层采用的链表法来解决冲突。即使装载因子和 Hash函数设计的再合理，随着数据量的增加也会出现链表过长的情况，一旦链表过长，严重影响了 HashMap 的性能。

在 JDK1.8 中对 HashMap 底层做了优化。当链表长度大于 8 时，链表就转化为红黑树，当链表小于 8 时，将红黑树转化为链表。因为当链表过长的时候，查找的效率将会变慢，利用红黑树快速增删改查的特性，可以提高  HashMap 的性能，而链表不长时，红黑树的快速增删改查的特性就不太明显，并且红黑树的还有维护成本，因此当链表不长时，不需要将链表转化为红黑树。
## 扰动函数

在 HashMap 存放元素时候有这样一段代码来处理哈希值，这是 JDK1.8 的散列值扰动函数，用于优化散列效果；
```java
static final int hash(Object key) {
	int h;
	return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
```
#### 为什么使用扰动函数?
**使用扰动函数就是为了增加随机性，让数据元素更加均衡的散列，减少碰撞。**
理论上来说字符串的 hashCode 是一个 int 类型值，那可以直接作为数组下标了，且不会出现碰撞。但是这个 hashCode 的取值范围是 [-2147483648, 2147483647]，有将近40亿的长度，谁也不能把数组初始化的这么大，内存也是放不下的。

我们默认初始化的 Map 大小是16个长度 DEFAULT_INITIAL_CAPACITY = 1 << 4，所以获取的 Hash 值并不能直接作为下标使用，需要与数组长度进行取模运算得到一个下标值，也就是我们上面做的散列列子。

那么， hashMap 源码这里不只是直接获取哈希值，还进行了一次扰动计算，`(h = key.hashCode()) ^ (h >>> 16)`。把哈希值右移16位，也就正好是自己长度的一半，之后与原哈希值做异或运算，这样就混合了原哈希值中的高位和低位，增大了随机性。计算方式如下图；
![[hashMap扩容扰动函数.bmp]]

## 1.7和1.8的区别

#### 插入法：
- **JDK1.7用的是头插法**。
- **JDK1.8及之后使用的都是尾插法**

那么他们为什么要这样做呢？因为 JDK1.7 是用单链表进行的纵向延伸，当采用头插法时会容易出现逆序且环形链表死循环问题。但是在 JDK1.8 之后是因为加入了红黑树使用尾插法，能够避免出现逆序且链表死循环的问题。

#### 扩容后数据存储位置的计算方式
**在计算 hash 值的时候， JDK1.7 用了 9 次扰动处理= 4 次位运算+ 5 次异或，而 JDK1.8 只用了 2 次扰动处理= 1 次位运算+ 1 次异或。**
1. JDK1.7 的时候是直接用 hash 值和需要扩容的二进制数进行 & （这里就是为什么扩容的时候为啥一定必须是 2 的多少次幂的原因所在，因为如果只有 2 的 n 次幂的情况时最后一位二进制数才一定是 1 ，这样能最大程度减少 hash 碰撞）（hash值 & length-1）

1.7 源码
```java
final int hash(Object k) {
		int h = hashSeed;
		if (0 != h && k instanceof String) {
			return sun.misc.Hashing.stringHash32((String) k);
		}

		h ^= k.hashCode();

		// This function ensures that hashCodes that differ only by
		// constant multiples at each bit position have a bounded
		// number of collisions (approximately 8 at default load factor).
		h ^= (h >>> 20) ^ (h >>> 12);
		return h ^ (h >>> 7) ^ (h >>> 4);
	}
```
2. JDK1.8 的时候直接用了 JDK1.7 的时候计算的规律，也就是**扩容前的原始位置+扩容的大小值=JDK1.8的计算方式**，而不再是 JDK1.7 的那种异或的方法。但是这种方式就相当于只需要判断 Hash 值的新增参与运算的位是 0 还是 1 就直接迅速计算出了扩容后的储存方式。

1.8 源码
```java
static final int hash(Object key) {
	int h;
	return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
```

![[hashMap扩容.bmp]]


#### 底层实现
1. JDK1.7 的时候使用的是**数组+ 单链表**的数据结构。
1. JDK1.8 及之后时，使用的是**数组+链表+红黑树**的数据结构（当链表的深度达到 8 的时候，也就是默认阈值，就会自动扩容把链表转成红黑树的数据结构来把时间复杂度从 O（n） 变成 O（logN） 提高了效率）